{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>What is Deep Learning???</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/V100.JPG)\n",
    "From: https://www.nvidia.com/en-us/data-center/v100/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Red_Divider.JPG)\n",
    "\n",
    "# <center>How Deep Neural Networks work<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural networks are patterned after neurons in the nervous system\n",
    "![title](./images/Brain_Neuron.JPG)\n",
    "From:https://towardsdatascience.com/the-differences-between-artificial-and-biological-neural-networks-a8b46db828b7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./images/Action_Potential.mp4\" controls  width=\"800\"  height=\"800\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"./images/Action_Potential.mp4\", width=800, height=800)\n",
    "# From https://gfycat.com/blandglamorousfrenchbulldog-action-potential-nerve-impulse-conduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "![title](./images/Red_Divider.JPG)\n",
    "\n",
    "#  \n",
    "\n",
    "# <center>How DNNs work - General Neural Network Architecture</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/NN_02.JPG)\n",
    "From: https://www.kdnuggets.com/2017/10/neural-network-foundations-explained-gradient-descent.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Red_Divider.JPG)\n",
    "\n",
    "# <center>Let's break the architecture down</center>\n",
    "#  \n",
    "## Single Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron consists of 4 parts.\n",
    "\n",
    "1. **Input value or One input layer:** The input layer of the perceptron is made of artificial input neurons and takes the initial data into the system for further processing.<br>\n",
    "\n",
    "<ins>**Weights and Bias:**</ins>\n",
    "\n",
    "2. **Weight:** It represents the dimension or strength of the connection between units. If the weight to node 1 to node 2 has a higher quantity, then neuron 1 has a more considerable influence on the neuron.<br>\n",
    "3. **Bias:** It is the same as the intercept added in a linear equation. It is an additional parameter whose task is to modify the output along with the weighted sum of the input to the other neuron.<br>\n",
    "4. **Activation Function:** A neuron can be activated or not, is determined by an activation function. The activation function calculates a weighted sum and further adding bias with it to give the result.<br>\n",
    "   \n",
    "<br>\n",
    "https://www.javatpoint.com/single-layer-perceptron-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Perceptron_02.JPG)\n",
    "From: https://www.javatpoint.com/single-layer-perceptron-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Perceptron_01.JPG)\n",
    "From: https://www.javatpoint.com/single-layer-perceptron-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Multilayer Perceptron</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/MLP_01.JPG)\n",
    "From: https://becominghuman.ai/multi-layer-perceptron-mlp-models-on-real-world-banking-data-f6dd3d7e998f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/NN_Iris.JPG)\n",
    "From: https://stats.stackexchange.com/questions/268561/example-of-backpropagation-for-neural-network-with-softmax-and-sigmoid-activatio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><u><i>What is going on in all of these layers and neurons???</i></u></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Perceptron_02.JPG)\n",
    "From: https://www.javatpoint.com/single-layer-perceptron-in-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/NN_03.JPG)\n",
    "From: https://juxt.pro/blog/posts/neural-maths.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><u><i>Activation Functions</u></i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Activation_Functions.JPG)\n",
    "From: https://towardsdatascience.com/complete-guide-of-activation-functions-34076e95d044"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax\n",
    "![title](./images/Softmax.JPG)\n",
    "From: https://i.stack.imgur.com/rFFsi.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Softmax_NN.JPG)\n",
    "From: https://gab41.lab41.org/entropic-ghosts-35670292bc87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Red_Divider.JPG)\n",
    "\n",
    "# <center>Let's walk through the process from start to finish</center>\n",
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/MNIST.JPG)\n",
    "![title](./images/MNIST_NN.JPG)\n",
    "From: https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center><u><i>Loss vs. Accuracy</u></i></center>\n",
    "![title](./images/Loss_vs_Accuracy.JPG)\n",
    "From: https://tensorflow.rstudio.com/tools/tensorboard/tensorboard/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><u><i>Hyperparameter Optimization</i></u></center>\n",
    "* Learning Rate\n",
    "* Number of epochs\n",
    "* Batch Size\n",
    "* Number of training samples\n",
    "* More or less layers with more or less neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "\n",
    "![title](./images/Red_Divider.JPG)\n",
    "\n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Convolutional Neural Networks</center>\n",
    "* Typically used with images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the simplest level (maybe oversimplying), computer vision can be broken down into just 3 categories:\n",
    "* Image classification\n",
    "* Object detection\n",
    "* Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/CV_Tasks.JPG)\n",
    "Image courtesy of Nvidia \"Fundamental of Deep Learning for Computer Vision\" course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We previously saw the general architecture for a vanilla neural network.  Let's look at the general architecture for a CNN.\n",
    "\n",
    "![title](./images/CNN_Architecture_General.JPG)\n",
    "From: https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNNs can get very complicated, very quickly.  This is an example of Google's Inception model.\n",
    "![title](./images/Inception_Model.JPG)\n",
    "From: https://adeshpande3.github.io/The-9-Deep-Learning-Papers-You-Need-To-Know-About.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>What makes up a CNNs</center>\n",
    "* Convolutions\n",
    "* Kernels (filters)\n",
    "* Pooling\n",
    "* Padding\n",
    "* Dropout\n",
    "* Fully connected layers\n",
    "* Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><u><i>Convolutions and Kernels</i></u></center>\n",
    "![title](./images/Convolution_General.JPG)\n",
    "From: https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks\n",
    "![title](./images/Convolution_Animated.gif)\n",
    "From: https://www.cc.gatech.edu/~san37/post/dlhc-cnn/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><u><i>Pooling</i></u></center>\n",
    "Downsamples the convolved feature (to save on processing time), reducing the number of dimensions of the feature map, while still preserving the most critical feature information.  \n",
    "![title](./images/Pooling_Animated.gif)\n",
    "From: https://developers.google.com/machine-learning/practica/image-classification/convolutional-neural-networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><u><i>Padding</i></u></center>\n",
    "\n",
    "Preserves the spatial dimensions of the volume such that the output volume size matches the input volume size.  \n",
    "![title](./images/Padding_Animated.gif)\n",
    "From: https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><u><i>Dropout</i></u></center>\n",
    "Regularization technique to prevent overfitting  \n",
    "![title](./images/Dropout_General.JPG)\n",
    "From: https://towardsdatascience.com/applied-deep-learning-part-4-convolutional-neural-networks-584bc134c1e2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center><u><i>Fully Connected Layer</i></u></center>\n",
    "Takes the results of the convolution/pooling process and uses them to classify the image into a label.  It's the step before softmax, but can occur earlier and multiple times (see the LeNet model).\n",
    "![title](./images/Softmax_NN.JPG)\n",
    "From: https://gab41.lab41.org/entropic-ghosts-35670292bc87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Putting it all together.</center>\n",
    "\n",
    "![title](./images/CNN_Architecture_General.JPG)\n",
    "From: https://towardsdatascience.com/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way-3bd2b1164a53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
