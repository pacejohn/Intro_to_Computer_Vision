{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Image Classification</center>\n",
    "\n",
    "Image classification is the process of classifying a whole image as one thing.  For example, dog, tree, cancerous lung.\n",
    "\n",
    "![title](./images/Sharks.JPG)\n",
    "\n",
    "## <center>A quick history on image classification</center>\n",
    "\n",
    "## ImageNet (www.image-net.org)\n",
    "\n",
    "ImageNet Large Scale Visual Recognition Challenge (ILSVRC) - Large competition to classify images into 1,000 classes.  Training set had 1.2 million images.\n",
    "\n",
    "![title](./images/ImageNet.JPG)\n",
    "\n",
    "## Over the years, CNNs have become more complicated, more powerful, and require a lot more computing power to train.\n",
    "\n",
    "* LeNet-5 (1998) - 2 convolutions, 3 FC layers - 60,000 parameters\n",
    "\n",
    "* AlexNet (2012) - 60,000,000 parameters\n",
    "\n",
    "* VGG-16 (2014) - <b><u><i>138,000,000 parameters</b></u></i>\n",
    "\n",
    "* Inception-v3 (2015) - 24,000,000 parameters\n",
    "\n",
    "* ResNet-50 (2015) - 26,000,000 parameters\n",
    "\n",
    "\n",
    "![title](./images/LeNet.JPG)\n",
    "60,000 parameters\n",
    "\n",
    "![title](./images/AlexNet.JPG)\n",
    "60,000,000 parameters\n",
    "\n",
    "![title](./images/Inception_V3.JPG)\n",
    "24,000,000 parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Red_Divider.JPG)\n",
    "\n",
    "# <center>Preprocessing</center>\n",
    "For most CNNs, preprocessing of images is either required or is a good idea.\n",
    "\n",
    "## MNIST dataset\n",
    "![title](./images/MNIST.png)\n",
    "\n",
    "https://www.mdpi.com/2076-3417/9/15/3169\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Image resizing</u>\n",
    "\n",
    "Classification\n",
    "* For LeNet, images must be 28x28.\n",
    "* For AlexNet, images must be 256x256 (or 227x227 depending on implementation).\n",
    "* For GoogleNet, images must be 224x224.\n",
    "\n",
    "Object Detection\n",
    "* For Faster-RCNN, images must be 600x1024.\n",
    "\n",
    "If the images are not sized correctly, most implementations will resize them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <u>Augmentation</u>\n",
    "\n",
    "Augmentation is the process of making copies of images, then making changes to those images.  The main purposes are to (1) create a larger dataset of varied images and (2) introduce new images into the training set that will help the model be able to generalize better.\n",
    "\n",
    "## Examples of augmentation (not a complete list)\n",
    "\n",
    "### * Horizontal Flip\n",
    "![title](./images/Horizontal_Flip.JPG)\n",
    "\n",
    "### * Vertical Flip\n",
    "![title](./images/Vertical_Flip.JPG)\n",
    "\n",
    "### * Noise\n",
    "![title](./images/Noise.JPG)\n",
    "\n",
    "### * Rotate\n",
    "![title](./images/Rotate.JPG)\n",
    "\n",
    "### * Translate\n",
    "![title](./images/Translate.JPG)\n",
    "\n",
    "### * Zoom/Stretch\n",
    "![title](./images/Zoom_Stretch.JPG)\n",
    "\n",
    "### * Blur\n",
    "![title](./images/Blur.JPG)\n",
    "\n",
    "### * Random Erasing\n",
    "![title](./images/Random_Erasing.JPG)\n",
    "\n",
    "Images from https://github.com/codebox/image_augmentor and https://arxiv.org/pdf/1708.04896.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Red_Divider.JPG)\n",
    "\n",
    "# <center>The Importance of Training on a Representative Dataset</center>\n",
    "\n",
    "If you don't train on a representative dataset, you results will be poor.  Augmentation can help with this.\n",
    "\n",
    "Examples of how training on the right or wrong data can be beneficial.\n",
    "\n",
    "https://cloud.google.com/vision/docs/drag-and-drop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Tools to be able to do Image Classification</u>\n",
    "\n",
    "\n",
    "## <font color='red'>Google Vision AI</font> - https://cloud.google.com/vision/docs/drag-and-drop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'> Nvidia Digits</font>\n",
    "\n",
    "https://github.com/NVIDIA/DIGITS/blob/master/docs/GettingStarted.md\n",
    "\n",
    "### Let's try some training and testing with Nvidia Digits!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
