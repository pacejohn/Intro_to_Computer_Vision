{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Object Detection</center>\n",
    "\n",
    "\n",
    "# <center>What is Object Detection?</center>\n",
    "Object detection is the process of finding and delineating specific objects within an image.  For example, finding which specific part of the image is a tumor or finding letters while someone is signing in American Sign Language.\n",
    "\n",
    "* Example of detection of brain tumor.  The red boxes are the \"ground truth.\"  The green boxes are the predicted region.\n",
    "![title](./images/Brain_Tumor_Bounding_Boxes.JPG)\n",
    "\n",
    "# <i>The biggest pain about object detection is labeling the images with bounding boxes!!!!</i>\n",
    "\n",
    "I use something called \"labelImg\".  There are other programs that can be used, but I like this one.\n",
    "https://github.com/tzutalin/labelImg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./images/ASL_Compressed.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"./images/ASL_Compressed.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Red_Divider.JPG)\n",
    "\n",
    "# </center>How does Object Detection Work?<center>\n",
    "\n",
    "Image classification involves predicting the class of one object in an image. Object localization refers to identifying the location of one or more objects in an image and drawing abounding box around their extent. Object detection combines these two tasks and localizes and classifies one or more objects in an image.\n",
    "\n",
    "From: https://machinelearningmastery.com/object-recognition-with-deep-learning/\n",
    "\n",
    "## Faster-RCNN\n",
    "* Very popular\n",
    "* Very accurate\n",
    "* Computationally expensive to train\n",
    "* Inference is slow, especially as model gets bigger - typically needs a GPU\n",
    "\n",
    "How it works - the simple version.  \n",
    "![title](./images/Faster_RCNN.JPG)\n",
    "Image from https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e\n",
    "\n",
    "This website is incredibly easy and helpful to set up an Object Detection pipeline using TensorFlow with Faster-RCNN.\n",
    "https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\n",
    "\n",
    "\n",
    "## YOLO (You Only Look Once)\n",
    "* Very popular\n",
    "* Not as accurate as Faster-RCNN\n",
    "* Not as computationally expensive to train\n",
    "* Inference is very, very fast\n",
    "* Struggles with small objects\n",
    "\n",
    "How it works - A single CNN predicts the bounding boxes and the class probabilities for these boxes, rather than multiple CNNs.\n",
    "![title](./images/YOLO_Image.JPG)\n",
    "Image from https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./images/YOLO_Compressed.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"./images/YOLO_Compressed.mp4\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Video from https://www.youtube.com/watch?time_continue=94&v=eeIEH2wjvhg&feature=emb_logo\n",
    "\n",
    "## MobileNetV2\n",
    "* Probably most common CNN used for inference on mobile devices\n",
    "* Not as accurate as Faster-RCNN\n",
    "* Not as computationally expensive to train\n",
    "* Inference is very, very fast and light weight\n",
    "\n",
    "How it works - Check out Google's blog for details - https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html\n",
    "![title](./images/SSD_MobileNet_Image.png)\n",
    "\n",
    "Image from https://ai.googleblog.com/2018/04/mobilenetv2-next-generation-of-on.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./images/SSD_Short_Video_Compressed.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"./images/SSD_Short_Video_Compressed.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of YOLOv2, SSD MobileNet, and Faster-RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./images/Comparison_Short_Video_Compressed.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "Video(\"./images/Comparison_Short_Video_Compressed.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./images/Red_Divider.JPG)\n",
    "\n",
    "# <center>Transfer Learning</center>\n",
    "A <i>pre-trained model</i> is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task. You either use the pretrained model as is or use transfer learning to customize this model to a given task.\n",
    "\n",
    "The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\n",
    "\n",
    "Many pretrained models can be downloaded from the Google Model Zoo.  https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\n",
    "\n",
    "\n",
    "\n",
    "Examples of some pretrained models datasets:\n",
    "* COCO - Common Objects in Context (http://cocodataset.org/#home)\n",
    "330K images (>200K labeled), 1.5 million object instances, 80 object categories, 91 stuff categories, 5 captions per image, 250,000 people with keypoints\n",
    "\n",
    "* Open Images v4 (https://storage.googleapis.com/openimages/web/index.html)\n",
    "Open Images is a dataset of ~9M images that have been annotated with image-level labels and object bounding boxes.  The training set of V4 contains 14.6M bounding boxes for 600 object classes on 1.74M images, making it the largest existing dataset with object location annotations. The boxes have been largely manually drawn by professional annotators to ensure accuracy and consistency. The images are very diverse and often contain complex scenes with several objects (8.4 per image on average). Moreover, the dataset is annotated with image-level labels spanning thousands of classes.\n",
    "\n",
    "\n",
    "From https://www.tensorflow.org/tutorials/images/transfer_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
